{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3f4136-a616-4342-9a84-6620b1378ebf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gesture recognition\n",
    "# Kaszti Dávid\n",
    "# Kézi gesztusfelismerés PowerPoint vezérélésére\n",
    "# Hand gesture recognition for controlling PowerPoint\n",
    "# CNN tanítás Python Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10e499-ed6d-42f9-a754-d680abfa150d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.optimizers.optimizer_v2.adam import Adam\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c21f3-6752-467a-9e4d-bdef30b1f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                 rotation_range=10,\n",
    "                                 zoom_range=0.1)\n",
    "img_size = 64\n",
    "train_dir = r'C:\\Users\\admin\\Desktop\\modellek\\v4\\6464_gray\\training\\train'\n",
    "test_dir = r'C:\\Users\\admin\\Desktop\\modellek\\v4\\6464_gray\\training\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a268649-bbbc-44a6-bd00-7726b84936fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_database(traindir, testdir):\n",
    "    train_datagen = datagen.flow_from_directory(\n",
    "            traindir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=64,\n",
    "            class_mode='categorical',\n",
    "            color_mode='grayscale',\n",
    "          )\n",
    "\n",
    "    val_datagen = datagen.flow_from_directory(\n",
    "            testdir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=64,\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "        )\n",
    "    return train_datagen, val_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6c434-09d6-4ea8-b58e-49af0d66227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen, val_datagen = set_database(train_dir, test_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c33ff-eff8-41cf-bb58-735b6f31ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu',\n",
    "                         input_shape=(img_size, img_size, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', metrics.Recall(), metrics.Precision()])\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, \"cnn_model3.png\", show_shapes=True, dpi=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf60bbf-46eb-49e2-8615-7a2c376f07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience = 5)\n",
    "log = model.fit(train_datagen, epochs=epochs, batch_size=batch_size, validation_data=val_datagen, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff2f22-15f8-49e9-aa11-ae27c83ce5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log.history['accuracy'])\n",
    "plt.plot(log.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(log.history['loss'])\n",
    "plt.plot(log.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501a8fc-9be4-4902-8067-4ec61f317bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=64,\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "            shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11daeb4-8474-46e9-bdca-e29de36fadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(val_datagen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Metrics')\n",
    "target_names = ['A', 'B', 'H', 'L', 'P', 'Q']\n",
    "print(classification_report(val_datagen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f2bd3-7bc9-41b4-baac-52f5ce4d2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(val_datagen.classes, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=target_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0fcce-ba3c-4dc7-b936-a7d552978257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test_15.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
