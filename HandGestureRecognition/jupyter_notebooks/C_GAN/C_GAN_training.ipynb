{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd7c2bf",
   "metadata": {},
   "source": [
    "# Gesture recognition\n",
    "# Kaszti Dávid\n",
    "# Kézi gesztusfelismerés PowerPoint vezérélésére\n",
    "# Hand gesture recognition for controlling PowerPoint\n",
    "# Pix2Pix training Python Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca2847",
   "metadata": {},
   "source": [
    "# GAN hálózat alapja:\n",
    "https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10e499-ed6d-42f9-a754-d680abfa150d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dropout, Concatenate, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.optimizers.optimizer_v2.adam import Adam\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "import skimage.exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845935a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_randomly_rectangle(img,rate,shape):\n",
    "    y1 = np.random.randint(0, 64 - shape[0], 1)\n",
    "    y2 = y1 + shape[0]\n",
    "    x1 = np.random.randint(0, 64 - shape[1], 1)\n",
    "    x2 = x1 + shape[1]\n",
    "    masked_img = img.copy()\n",
    "    cpx = x1\n",
    "    while y1 < y2:\n",
    "        while x1 < x2:\n",
    "            masked_img[ x1,y1, :] = masked_img[ x1,y1,  :] * rate\n",
    "            x1 = x1 + 1\n",
    "        x1 = cpx\n",
    "        y1 = y1 + 1\n",
    "    return masked_img\n",
    "\n",
    "\n",
    "def mask_randomly_lines_pattern(img,rate,shape):\n",
    "    base = img.copy()\n",
    "    x1, y1 = np.random.randint(1, 14), np.random.randint(1, 14)\n",
    "    x2, y2 = np.random.randint(50, 63), np.random.randint(1, 14)\n",
    "    alpha = 1 - rate\n",
    "    for index in range(np.random.randint(1, 5)):\n",
    "        thickness = np.random.randint(3, 6)\n",
    "        color = (0, 0, 0)\n",
    "        cv2.line(base, (x1, y1 + index * 14), (x2, y2 + index * 14), color, thickness)\n",
    "    r = cv2.addWeighted(base, alpha, img, 1 - alpha, 0)\n",
    "    return r\n",
    "\n",
    "\n",
    "def mask_randomly_irregular(img,rate,shape, rng):\n",
    "    noise = rng.integers(230, 255, (img.shape[0], img.shape[1]), np.uint8, True)\n",
    "    blured_image = cv2.GaussianBlur(noise, (0, 0), sigmaX=13, sigmaY=13, borderType=cv2.BORDER_DEFAULT)\n",
    "    stretch = skimage.exposure.rescale_intensity(blured_image, in_range='image', out_range=(0, 255)).astype(np.uint8)\n",
    "    thresh = cv2.threshold(stretch, 170, 255, cv2.THRESH_BINARY)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (12, 12))\n",
    "    mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.merge([mask, mask, mask])\n",
    "    result = cv2.add(img, mask)\n",
    "    result = np.where(mask == (255, 255, 255), img * rate, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paired_dataset(source, destination):\n",
    "    seedval = 917\n",
    "    rng = np.random.default_rng(seed=seedval)\n",
    "\n",
    "    for filename in os.listdir(source):\n",
    "        img = cv2.imread(os.path.join(source, filename))\n",
    "        rate = round(random.uniform(0.1, 0.3), 2)\n",
    "        shape_one = np.random.randint(20, 45, 1)\n",
    "        shape_two = np.random.randint(20, 45, 1)\n",
    "        shape = (shape_one, shape_two)\n",
    "        selector = np.random.randint(1,3)\n",
    "        if selector == 1:\n",
    "            img = mask_randomly_rectangle(img,rate,shape)\n",
    "        elif selector == 2:\n",
    "            img = mask_randomly_irregular(img, rate, shape, rng)\n",
    "        else:\n",
    "            img = mask_randomly_lines_pattern(img,rate,shape)\n",
    "        cv2.imwrite(destination + filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input_layer, n_filters, batchnorm=True, trainable=True, stride_shape=(2, 2)):\n",
    "    initializer = RandomNormal(stddev=0.02)\n",
    "    block = Conv2D(n_filters, (4, 4), strides=stride_shape, padding='same', kernel_initializer=initializer)(input_layer)\n",
    "    if batchnorm and trainable:\n",
    "        block = BatchNormalization()(block, training=True)\n",
    "    elif batchnorm:\n",
    "        block = BatchNormalization()(block)\n",
    "    block = LeakyReLU(alpha=0.2)(block)\n",
    "    return block\n",
    "\n",
    "\n",
    "def decoder_block(input_layer, skip_in, n_filters, dropout=False):\n",
    "    initializer = RandomNormal(stddev=0.02)\n",
    "    block = Conv2DTranspose(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=initializer)(input_layer)\n",
    "    block = BatchNormalization()(block, training=True)\n",
    "    if dropout:\n",
    "        block = Dropout(0.5)(block, training=True)\n",
    "    block = Concatenate()([block, skip_in])\n",
    "    block = Activation('relu')(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8632b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape):\n",
    "    initializer = RandomNormal(stddev=0.02)\n",
    "    input_source = Input(shape=image_shape)\n",
    "    input_target = Input(shape=image_shape)\n",
    "    merged = Concatenate()([input_source, input_target])\n",
    "    layer = encoder_block(merged,64,False)\n",
    "    layer = encoder_block(layer,128,True)\n",
    "    layer = encoder_block(layer,256,True)\n",
    "    layer = encoder_block(layer,512,True)\n",
    "    one_shape = (1,1)\n",
    "    layer = encoder_block(layer,512,True,True, one_shape)\n",
    "    layer = Conv2D(1, (4,4), padding='same', kernel_initializer=initializer)(layer)\n",
    "    patch = Activation('sigmoid')(layer)\n",
    "    model = Model([input_source, input_target], patch)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    model.summary()\n",
    "    keras.utils.plot_model(model, \"d_model.png\", show_layer_activations=False ,expand_nested=False, show_shapes=True, dpi=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(256, 256, 3)):\n",
    "    initializer = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    encoder1 = encoder_block(in_image, 64, batchnorm=False)\n",
    "    encoder2 = encoder_block(encoder1, 128)\n",
    "    encoder3 = encoder_block(encoder2, 256)\n",
    "    encoder4 = encoder_block(encoder3, 512)\n",
    "    encoder5 = encoder_block(encoder4, 512)\n",
    "    bottleneck_layer = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=initializer)(encoder5)\n",
    "    bottleneck_layer = Activation('relu')(bottleneck_layer)\n",
    "    decoder1 = decoder_block(bottleneck_layer, encoder5, 512, dropout=True)\n",
    "    decoder2 = decoder_block(decoder1, encoder4, 512)\n",
    "    decoder3 = decoder_block(decoder2, encoder3, 256)\n",
    "    decoder4 = decoder_block(decoder3, encoder2, 128)\n",
    "    decoder5 = decoder_block(decoder4, encoder1, 64)\n",
    "    final_layer = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', kernel_initializer=initializer)(decoder5)\n",
    "    out_image = Activation('tanh')(final_layer)\n",
    "    model = Model(in_image, out_image)\n",
    "    model.summary()\n",
    "    keras.utils.plot_model(model, \"g_model.png\", show_shapes=True, dpi=128)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    in_src = Input(shape=image_shape)\n",
    "    gen_out = g_model(in_src)\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1, 100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a268649-bbbc-44a6-bd00-7726b84936fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    trainA, trainB = dataset\n",
    "    ix = randint(0, trainA.shape[0], n_samples)\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    X = g_model.predict(samples)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c21f3-6752-467a-9e4d-bdef30b1f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paired_dataset(basepath, maskedpath):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "\n",
    "    for fileName in os.listdir(basepath):\n",
    "        image = cv2.imread(basepath + fileName)\n",
    "        X2.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    for fileName in os.listdir(maskedpath):\n",
    "        image = cv2.imread(maskedpath + fileName)\n",
    "        X1.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    X1 = np.array(X1)\n",
    "    X2 = np.array(X2)\n",
    "    X1 = (X1.astype(np.float32) - 127.5) / 127.5\n",
    "    X2 = (X2.astype(np.float32) - 127.5) / 127.5\n",
    "    return [X1, X2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    trainA, trainB = dataset\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    for i in range(n_steps):\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        print(\"Steps: %d/%d || real d loss: %.3f || fake d loss: %.3f || g loss: %.3f\" % (i + 1, n_steps, d_loss1, d_loss2, g_loss))\n",
    "        if i == 20:\n",
    "            filename = 'model_%06d.h5' % (i + 1)\n",
    "            g_model.save(filename)\n",
    "            print('Saved: ' + filename)\n",
    "        if (i + 1) % (bat_per_epo * 10) == 0:\n",
    "            filename = 'model_%06d.h5' % (i + 1)\n",
    "            g_model.save(filename)\n",
    "            print('Saved: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(base_data, masked_data):\n",
    "    dataset = load_paired_dataset(base_data, masked_data)\n",
    "    print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "    image_shape = dataset[0].shape[1:]\n",
    "    d_model = define_discriminator(image_shape)\n",
    "    g_model = define_generator(image_shape)\n",
    "    gan_model = define_gan(g_model, d_model, image_shape)\n",
    "    train(d_model, g_model, gan_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8b303",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "source = \"C:/Users/admin/Desktop/unified_rgb_extended/\"\n",
    "destination = \"C:/Users/admin/Desktop/arnyekolasok/mask_mixed_extended_pattern_lines_v2/\"\n",
    "#create_paired_dataset(source, destination)\n",
    "run_train(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151e034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
